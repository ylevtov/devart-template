Another great thing about working with Max For Live is that you can do incredibly deep integration of visuals and music. Exactly like with the DMX lighting (see 'Let there be light' post, below) we can use any information from any track in Live to trigger events in the visuals being generated by Jitter.  

This is something I've been exploring recently with my band's music set-up - pre-producing visual themes in Jitter for each song and linking their visual parameters directly to various MIDI-note feeds and effect parameters in Live using the M4L API. The benefits here are two-fold:
1. The visual engine (Jitter) has direct access to the music engine (Live), meaning that syncing video and audio events becomes trivial
2. Because the visuals effectively generate themselves based on the music, the performer is automatically creating their own visual show _without any extra effort_  

These principals are used in the projected visuals for this installation, except that instead of a single performer triggering instruments and effects (and therefore manipulating the visuals) they are being inadvertendly controlled by the visitors via their collective interactions.  

We wanted to keep the visuals quite simple, giving each song is own theme and crossfading between the two when the songs transition from one to the other.  

I started off with some patches from Andrew Benson's ever-inspiring [Jitter Recipes]('http://cycling74.com/2006/02/14/jitter-recipes-book-2/') and went on to make modifications that connected them to the music as much as possible.  

![Jitter Visuals 1](project_images/visuals-screenshots-1.jpg?raw=true "Jitter Visuals 1")

![Jitter Visuals 2](project_images/visuals-screenshots-2.jpg?raw=true "Jitter Visuals 2")

![Jitter Visuals 3](project_images/visuals-screenshots-3.jpg?raw=true "Jitter Visuals 3")

![Jitter Visuals 4](project_images/visuals-screenshots-4.jpg?raw=true "Jitter Visuals 4")

![Jitter Visuals 5](project_images/visuals-screenshots-5.jpg?raw=true "Jitter Visuals 5")